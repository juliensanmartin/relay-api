# ğŸ” Observability Stack - Where to Look for What

**The Confusion:** You have Jaeger, Prometheus, Grafana, and Pino logs. Where do you look when something goes wrong?

**The Answer:** Each tool serves a specific purpose. Here's your definitive guide.

---

## ğŸ“Š The Three Pillars of Observability

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  YOUR OBSERVABILITY STACK                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   METRICS       â”‚     TRACES      â”‚        LOGS             â”‚
â”‚  (What & How    â”‚   (Where &      â”‚    (Why & Details)      â”‚
â”‚   Much)         â”‚    When)        â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Prometheus     â”‚     Jaeger      â”‚      Pino               â”‚
â”‚  (Collect)      â”‚   (Visualize)   â”‚   (Raw output)          â”‚
â”‚       â†“         â”‚                 â”‚                         â”‚
â”‚   Grafana       â”‚                 â”‚                         â”‚
â”‚  (Visualize)    â”‚                 â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Quick Decision Tree

**"Where should I look?"**

```
Is it about...

ğŸ“ˆ PERFORMANCE & TRENDS?
   â†’ Prometheus (http://localhost:9090) or Grafana (http://localhost:3009)
   Examples: "How many requests per second?"
             "Is cache hit rate going down?"
             "What's my P95 latency?"

ğŸ” A SPECIFIC REQUEST FLOW?
   â†’ Jaeger (http://localhost:16686)
   Examples: "Why did this user's login take 5 seconds?"
             "Which service failed in this request?"
             "Where's the bottleneck in this API call?"

ğŸ› DEBUGGING / ERROR DETAILS?
   â†’ Terminal logs (docker compose logs)
   Examples: "What was the exact error message?"
             "What variables were passed to this function?"
             "Did the database query succeed?"

ğŸ“Š DASHBOARDS & ALERTING?
   â†’ Grafana (http://localhost:3009)
   Examples: "I want a dashboard for my team"
             "I need alerts when cache hit rate < 50%"
             "Show me service health at a glance"
```

---

## 1ï¸âƒ£ Prometheus (Port 9090) - "What & How Much?"

### **Purpose:** Collect and query numerical metrics over time

**When to use:**

- âœ… "How many cache hits happened in the last hour?"
- âœ… "What's my request rate across all services?"
- âœ… "Is my database response time increasing?"
- âœ… "What's my error rate?"

### **What it shows:**

- Counters (e.g., `cache_hits_total`, `http_requests_total`)
- Gauges (e.g., memory usage, active connections)
- Histograms (e.g., request duration buckets)
- Time-series data (trends over time)

### **URL:** http://localhost:9090

### **How to use it:**

#### Example 1: Cache Hit Rate

```promql
# Total cache hits in last 5 minutes
sum(rate(cache_hits_total[5m]))

# Total cache operations (hits + misses)
sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m]))

# Cache hit rate percentage
(sum(rate(cache_hits_total[5m])) /
 (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])))) * 100
```

#### Example 2: Request Rate by Service

```promql
# Requests per second for post-service
rate(http_request_duration_ms_count{app="relay-post-service"}[1m])

# Total requests across all services
sum(rate(http_request_duration_ms_count[1m]))
```

#### Example 3: P95 Latency (95th percentile)

```promql
# 95% of requests complete within this time
histogram_quantile(0.95,
  rate(http_request_duration_ms_bucket[5m]))
```

#### Example 4: Error Rate

```promql
# Requests with 5xx status codes
sum(rate(http_request_duration_ms_count{code=~"5.."}[5m]))
```

### **Pros:**

- âœ… Powerful query language (PromQL)
- âœ… Great for trends and patterns
- âœ… Efficient time-series storage

### **Cons:**

- âŒ Not user-friendly for non-technical users
- âŒ Basic visualization (use Grafana instead)
- âŒ Doesn't show individual request details

---

## 2ï¸âƒ£ Grafana (Port 3009) - "Pretty Dashboards & Alerts"

### **Purpose:** Visualize Prometheus metrics with beautiful dashboards

**When to use:**

- âœ… "I want a dashboard to monitor my services"
- âœ… "I need to show metrics to my team"
- âœ… "Alert me when something goes wrong"
- âœ… "What's the health of my system right now?"

### **What it shows:**

- Same data as Prometheus, but with:
  - Beautiful charts and graphs
  - Multiple metrics on one dashboard
  - Real-time updates
  - Alerts and notifications

### **URL:** http://localhost:3009 (admin/admin)

### **How to use it:**

#### Step 1: Create a Dashboard

1. Click "+" â†’ "Dashboard"
2. Click "Add visualization"
3. Select "Prometheus" as data source
4. Enter a PromQL query (same as Prometheus examples above)
5. Choose visualization type (line chart, gauge, stat, etc.)

#### Example Dashboard: "Post Service Health"

**Panel 1: Request Rate**

```promql
Query: rate(http_request_duration_ms_count{app="relay-post-service"}[1m])
Visualization: Line chart
Title: "Requests per Second"
```

**Panel 2: Cache Hit Rate**

```promql
Query: (sum(rate(cache_hits_total[5m])) /
        (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])))) * 100
Visualization: Gauge (0-100%)
Title: "Cache Hit Rate"
Alert: If < 50% for 5 minutes
```

**Panel 3: P95 Latency**

```promql
Query: histogram_quantile(0.95, rate(http_request_duration_ms_bucket[5m]))
Visualization: Line chart
Title: "95th Percentile Response Time"
Alert: If > 500ms for 5 minutes
```

**Panel 4: Active Redis Keys**

```promql
Query: redis_keys_total (if you add this metric)
Visualization: Stat
Title: "Cached Keys"
```

#### Step 2: Set Up Alerts

1. In any panel, click "Alert" tab
2. Define condition (e.g., cache hit rate < 50%)
3. Configure notification channel (Slack, email, etc.)

### **Pros:**

- âœ… Beautiful, shareable dashboards
- âœ… Great for monitoring at a glance
- âœ… Alerts and notifications
- âœ… Non-technical team members can use it

### **Cons:**

- âŒ Still shows aggregated data (not individual requests)
- âŒ Requires setup time to create dashboards

---

## 3ï¸âƒ£ Jaeger (Port 16686) - "Where & When?"

### **Purpose:** Trace individual requests across multiple services

**When to use:**

- âœ… "Why is THIS specific request slow?"
- âœ… "Which service is the bottleneck?"
- âœ… "Where did this error happen in the request flow?"
- âœ… "How long did the database query take?"
- âœ… "Did the request reach all services?"

### **What it shows:**

- Complete journey of a single request
- Timeline of operations (spans)
- Service dependencies
- Latency breakdown by operation
- Errors and exceptions

### **URL:** http://localhost:16686

### **How to use it:**

#### Example 1: Debug a Slow Request

**Scenario:** User reports slow post loading

1. **Go to Jaeger UI** â†’ http://localhost:16686
2. **Select Service:** "api-gateway"
3. **Click "Find Traces"**
4. **Look for slow traces** (duration > 500ms)
5. **Click on a trace** to see the waterfall view

**What you'll see:**

```
api-gateway (250ms total)
  â”œâ”€ POST /api/posts (5ms)
  â”‚  â””â”€ Authorization check (2ms)
  â”‚
  â”œâ”€ HTTP POST to post-service (240ms)  â† BOTTLENECK!
  â”‚  â”œâ”€ Redis GET posts:all (200ms)  â† WHY SO SLOW?
  â”‚  â””â”€ PostgreSQL SELECT (35ms)
  â”‚
  â””â”€ Response serialization (5ms)
```

**Diagnosis:** Redis operation took 200ms (should be ~5ms). Check Redis health!

#### Example 2: Find Where an Error Occurred

**Scenario:** User got 500 error

1. **Select Service:** "api-gateway"
2. **Add Tag:** `error=true`
3. **Click "Find Traces"**
4. **Click on failed trace**

**What you'll see:**

```
api-gateway (ERROR)
  â””â”€ POST /api/posts/:id/upvote
     â””â”€ HTTP POST to post-service (ERROR)
        â””â”€ PostgreSQL INSERT upvotes (ERROR)
           Error: "duplicate key violation"  â† ROOT CAUSE
```

#### Example 3: Understand Service Dependencies

1. **Click "System Architecture"** tab
2. See visual graph of how services call each other
3. Identify critical paths and dependencies

### **Pros:**

- âœ… See EXACTLY what happened in a single request
- âœ… Find bottlenecks instantly
- âœ… Understand service dependencies
- âœ… Debug production issues

### **Cons:**

- âŒ Only shows individual requests (not trends)
- âŒ Requires you to find a specific trace
- âŒ Storage intensive (can't store all traces forever)

---

## 4ï¸âƒ£ Pino Logs - "Why & Details?"

### **Purpose:** Detailed, structured logs for debugging

**When to use:**

- âœ… "What was the exact error message?"
- âœ… "What were the variable values?"
- âœ… "Did this function execute?"
- âœ… "What SQL query was run?"
- âœ… "What was in the request body?"

### **What it shows:**

- Structured JSON logs with context
- Debug information
- Error stack traces
- Custom log messages from your code

### **How to view:**

#### In Development:

```bash
# All services
docker compose logs -f

# Specific service
docker compose logs -f post-service

# Filter for errors
docker compose logs post-service | grep -i error

# Filter for cache operations
docker compose logs post-service | grep -i cache
```

#### Example Log Output:

```json
{
  "level": 30,
  "time": 1696348800000,
  "msg": "Cache HIT",
  "key": "posts:all",
  "pid": 1,
  "hostname": "post-service"
}

{
  "level": 50,
  "time": 1696348801000,
  "msg": "Error upvoting post",
  "err": {
    "type": "DatabaseError",
    "message": "duplicate key violation",
    "stack": "..."
  },
  "postId": 123,
  "userId": 456
}
```

### **Pros:**

- âœ… Most detailed information
- âœ… Includes stack traces and error details
- âœ… Can add custom context
- âœ… Good for debugging during development

### **Cons:**

- âŒ Hard to search in production (need a log aggregator like ELK stack)
- âŒ Overwhelming amount of data
- âŒ Not good for trends or patterns

---

## ğŸ¯ Real-World Scenarios

### Scenario 1: "My API is slow!"

**Step 1: Prometheus** â†’ Check overall trends

```promql
histogram_quantile(0.95, rate(http_request_duration_ms_bucket[5m]))
```

**Finding:** P95 latency jumped from 50ms to 500ms at 2pm

**Step 2: Jaeger** â†’ Find a slow trace from ~2pm
**Finding:** Database query taking 400ms (usually 20ms)

**Step 3: Logs** â†’ Check database errors

```bash
docker compose logs post-service | grep -i "database"
```

**Finding:** "connection pool exhausted" errors

**Root Cause:** Database connection pool too small!

---

### Scenario 2: "Cache isn't working!"

**Step 1: Prometheus** â†’ Check cache metrics

```promql
rate(cache_hits_total[5m])
rate(cache_misses_total[5m])
```

**Finding:** 100% cache misses

**Step 2: Logs** â†’ Look for cache errors

```bash
docker compose logs post-service | grep -i "cache"
```

**Finding:** "Redis connection error"

**Step 3: Check Redis health**

```bash
docker compose ps redis
docker compose logs redis
```

**Root Cause:** Redis container crashed!

---

### Scenario 3: "User reported error on upvoting"

**Step 1: Jaeger** â†’ Search for user's request

- Service: api-gateway
- Operation: POST /api/posts/:id/upvote
- Time range: Last 1 hour
- Tag: error=true

**Finding:** Request failed in post-service

**Step 2: Logs** â†’ Get error details

```bash
docker compose logs post-service | grep -i "upvote" | grep -i "error"
```

**Finding:** "duplicate key violation" - user already upvoted

**Root Cause:** Frontend allowed double-click, should disable button!

---

## ğŸ“‹ Cheat Sheet: Where to Look

| Question                            | Tool               | Query/Action                                                                   |
| ----------------------------------- | ------------------ | ------------------------------------------------------------------------------ |
| **"How many requests per second?"** | Prometheus         | `rate(http_request_duration_ms_count[1m])`                                     |
| **"What's my cache hit rate?"**     | Prometheus/Grafana | `rate(cache_hits_total) / (rate(cache_hits_total) + rate(cache_misses_total))` |
| **"Why is this request slow?"**     | Jaeger             | Find trace, look at waterfall                                                  |
| **"Where's the bottleneck?"**       | Jaeger             | Find slowest span in trace                                                     |
| **"What error occurred?"**          | Jaeger + Logs      | Find error trace, check logs for details                                       |
| **"What's the error message?"**     | Logs               | `docker compose logs <service> \| grep error`                                  |
| **"Show me a dashboard"**           | Grafana            | Create dashboard with Prometheus queries                                       |
| **"Alert me if X happens"**         | Grafana            | Set up alert rule                                                              |
| **"Is Redis healthy?"**             | Prometheus/Logs    | Check `up` metric or health check logs                                         |
| **"What's the P95 latency?"**       | Prometheus/Grafana | `histogram_quantile(0.95, rate(..._bucket[5m]))`                               |

---

## ğŸ”„ The Workflow

**For Monitoring (Proactive):**

```
Daily: Grafana dashboards
  â†“ (notice trend)
Deep dive: Prometheus queries
  â†“ (identify time range)
Example: Jaeger trace from that time
  â†“ (find root cause)
Details: Logs
```

**For Debugging (Reactive):**

```
User reports issue
  â†“
Logs: Get error message and context
  â†“
Jaeger: Find the specific request trace
  â†“
Prometheus: Check if it's a pattern or one-off
  â†“
Grafana: Create dashboard to monitor the fix
```

---

## ğŸ¯ Next Steps: Set Up Your First Dashboard

### Create a "System Health" Dashboard in Grafana

1. **Go to Grafana:** http://localhost:3009 (admin/admin)
2. **Click "+" â†’ "Dashboard"**
3. **Add these panels:**

#### Panel 1: Request Rate (All Services)

- Query: `sum(rate(http_request_duration_ms_count[1m]))`
- Visualization: Line chart
- Legend: "Requests/sec"

#### Panel 2: Cache Hit Rate

- Query: `(sum(rate(cache_hits_total[5m])) / (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])))) * 100`
- Visualization: Gauge (0-100%)
- Thresholds: Red < 50%, Yellow 50-80%, Green > 80%

#### Panel 3: Service Status

- Query: `up{job="relay-services"}`
- Visualization: Stat
- Value: 1 = UP, 0 = DOWN

#### Panel 4: P95 Latency

- Query: `histogram_quantile(0.95, rate(http_request_duration_ms_bucket[5m]))`
- Visualization: Line chart
- Legend: "P95 Response Time (ms)"

4. **Save dashboard** as "System Health"

Now you have a single place to see your system's health at a glance! ğŸ“Š

---

## ğŸš€ Pro Tips

1. **Start with Grafana** for daily monitoring
2. **Use Jaeger** when something goes wrong with a specific request
3. **Check Logs** when you need the full error details
4. **Use Prometheus** when you need custom queries or deeper analysis

**Remember:**

- **Metrics** = What happened (trends)
- **Traces** = Where it happened (individual requests)
- **Logs** = Why it happened (details)

---

## ğŸ“š Further Reading

- [The Three Pillars of Observability](https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/)
- [Grafana Dashboard Best Practices](https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/best-practices/)
- [PromQL for Humans](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Jaeger Documentation](https://www.jaegertracing.io/docs/)

---

**You now have a complete observability stack! Use it to understand your system deeply. ğŸ”**

